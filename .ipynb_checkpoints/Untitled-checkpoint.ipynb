{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85407c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import os, pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6064b340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b8c71e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to CIFAR10_train_data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c31af8bfc34341be86cad7ad066b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting CIFAR10_train_data/cifar-10-python.tar.gz to CIFAR10_train_data\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to CIFAR10_test_data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a79488c42894cc08dabcd1ffe87bebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting CIFAR10_test_data/cifar-10-python.tar.gz to CIFAR10_test_data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = datasets.CIFAR10(\n",
    "    root = 'CIFAR10_train_data',\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True,\n",
    ")\n",
    "test_data = datasets.CIFAR10(\n",
    "    root = 'CIFAR10_test_data',\n",
    "    train = False,\n",
    "    transform = ToTensor(),\n",
    "    download = True,\n",
    ")\n",
    "\n",
    "loaders = {\n",
    "    'train': torch.utils.data.DataLoader(train_data,\n",
    "                                         batch_size=100,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=4),\n",
    "\n",
    "    'test': torch.utils.data.DataLoader(test_data,\n",
    "                                        batch_size=100,\n",
    "                                        shuffle=True,\n",
    "                                        num_workers=4),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef36da45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CorrelatedGroupSelector(nn.Module):\n",
    "    def __init__(self, input_dim, num_groups, group_size, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_groups = num_groups\n",
    "        self.group_size = group_size\n",
    "        self.temperature = temperature\n",
    "\n",
    "        # Learnable logits for group membership: [num_groups, input_dim]\n",
    "        self.group_logits = nn.Parameter(torch.randn(num_groups, input_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, input_dim)\n",
    "        Returns:\n",
    "            grouped_inputs: list of tensors [(batch, group_size), ...]\n",
    "            selection_mask: (num_groups, input_dim)\n",
    "        \"\"\"\n",
    "        # Gumbel-Softmax over inputs to create a soft group selection\n",
    "        gumbel_noise = -torch.log(-torch.log(torch.rand_like(self.group_logits)))\n",
    "        logits = self.group_logits + gumbel_noise\n",
    "        probs = F.softmax(logits / self.temperature, dim=-1)\n",
    "\n",
    "        # Use top-k per group to select group members\n",
    "        topk = torch.topk(probs, self.group_size, dim=-1)\n",
    "        selection_mask = torch.zeros_like(probs)\n",
    "        selection_mask.scatter_(1, topk.indices, 1.0)  # hard selection mask\n",
    "\n",
    "        grouped_inputs = []\n",
    "        for i in range(self.num_groups):\n",
    "            group = selection_mask[i] * x  # broadcasted (batch, input_dim)\n",
    "            grouped_inputs.append(group)\n",
    "\n",
    "        return grouped_inputs, selection_mask\n",
    "\n",
    "def compute_group_correlation(group):\n",
    "    \"\"\"\n",
    "    group: (batch_size, input_dim) where non-grouped values are 0\n",
    "    Returns: scalar correlation score (avg pairwise cosine)\n",
    "    \"\"\"\n",
    "    # Only non-zero cols\n",
    "    nonzero = (group.abs().sum(0) > 0)\n",
    "    group_vars = group[:, nonzero]\n",
    "    if group_vars.shape[1] < 2:\n",
    "        return torch.tensor(0.0, device=group.device)\n",
    "    normed = F.normalize(group_vars, dim=0)\n",
    "    corr = (normed.T @ normed) / normed.shape[0]\n",
    "    upper = torch.triu(corr, diagonal=1)\n",
    "    avg_corr = upper.sum() / (nonzero.sum() * (nonzero.sum() - 1) / 2 + 1e-6)\n",
    "    return avg_corr\n",
    "\n",
    "class SelectiveGroupModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_groups=4, group_size=4):\n",
    "        super().__init__()\n",
    "        self.selector = CorrelatedGroupSelector(input_dim, num_groups, group_size)\n",
    "        self.group_mlp = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(input_dim, 16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16, 1)\n",
    "            ) for _ in range(num_groups)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        groups, mask = self.selector(x)\n",
    "\n",
    "        # Compute correlation per group\n",
    "        correlations = torch.stack([compute_group_correlation(g) for g in groups])\n",
    "        _, selected_indices = torch.topk(-correlations, k=2)  # lowest 2 correlations\n",
    "\n",
    "        # Only update selected groups\n",
    "        outputs = []\n",
    "        for i, group in enumerate(groups):\n",
    "            if i in selected_indices:\n",
    "                out = self.group_mlp[i](group)\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    out = self.group_mlp[i](group)\n",
    "            outputs.append(out)\n",
    "\n",
    "        out = torch.cat(outputs, dim=1)\n",
    "        return out, correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9550b9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SelectiveGroupModel(input_dim=20, num_groups=5, group_size=4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52c1c581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 20])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.selector.group_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80b95c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectiveGroupModel(\n",
       "  (selector): CorrelatedGroupSelector()\n",
       "  (group_mlp): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=20, out_features=16, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=20, out_features=16, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=20, out_features=16, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Linear(in_features=20, out_features=16, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Linear(in_features=20, out_features=16, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7b9eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Flatten the input images\n",
    "        inputs_flat = inputs.view(inputs.size(0), -1)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs, corr_reg, scores = model(inputs_flat)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels) - 0.1 * corr_reg  # Adjust the weight of corr_reg as needed\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741031e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd0d681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7da7ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6b6e1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sys,os, glob\n",
    "from neo import io\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1cb16ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dirr = '/ems/elsc-labs/segev-i/yoni.leibner/PycharmProjects/Hippocampus_Basu/traces/'\n",
    "f = os.path.join(base_dirr, \".abf\")\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a1ecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = io.AxonIO(f)\n",
    "bl = r.read_block(lazy=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae818d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29c2bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eadb9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb60dea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b22207b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
